'''
Here in this script is the methods to load the process CrossDock dataset. This is based on image_dataset.py in the implementation of IDDPM
'''

from PIL import Image
import blobfile as bf
from mpi4py import MPI
import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset

from optdiffusion import crossdock_dataset,esm_dataset
from torch_geometric.data import DataLoader
from torch.utils.data import Subset

def load_data_smi( * , batch_size, vae_dir = None, dataset_save_path = None, data_dir=None, class_cond=False, deterministic=False, data_mood = "train"):
    datadir = data_dir
    print(f"now {data_mood}")
    dataset = crossdock_dataset.PocketLigandPairDataset(
        f'{datadir}',
        vae_path=f'{vae_dir}',
        save_path=f'{dataset_save_path}'
    )
    print("vae is :",vae_dir)
    datafull, subsets = split(dataset,'../Models/split_by_name.pt')
    train, val = subsets['train'], subsets['test']
    follow_batch = ['protein_pos', 'ligand_pos']
    if data_mood =="train":
        loader = DataLoader(
            train, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True, follow_batch=follow_batch
        )
        while True:
            yield from loader
    elif data_mood =="sample":
        loader = DataLoader(
            val, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True, follow_batch=follow_batch
        )
        print("now sample,num:",len(loader))
        while True:
            yield from loader

def load_data_esm( * , batch_size, vae_dir = None, dataset_save_path = None, data_dir=None, class_cond=False, deterministic=False, data_state = "train",sequence=None):
    datadir = data_dir

    if sequence is not None:
        dataset = esm_dataset.SequenceLigandPairDataset(
            f'{datadir}',
            vae_path=f'{vae_dir}',
            save_path=f'{dataset_save_path}',
            sequence = sequence,
        )
        print("vae is :",vae_dir)
        print("just training data")
        loader = DataLoader(
            dataset, batch_size=1, shuffle=False, num_workers=0, drop_last=True,
        )
        while True:
            yield from loader

    else:
        dataset = esm_dataset.SequenceLigandPairDataset(
            f'{datadir}',
            vae_path=f'{vae_dir}',
            save_path=f'{dataset_save_path}'
        )
        if data_state =="train":
            loader = DataLoader(
                dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True,
            )
            while True:
                yield from loader
        elif data_state =="sample":
            loader = DataLoader(
                dataset, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=False,
            )
            print("now sample,num:",len(loader))
            while True:
                yield from loader

def split(dataset,split_file):
    split_by_name = torch.load(split_file)
    split = {
        k: [dataset.name2id[n] for n in names if n in dataset.name2id]
        for k, names in split_by_name.items()
    }
    subsets = {k: Subset(dataset, indices=v) for k, v in split.items()}
    return dataset, subsets